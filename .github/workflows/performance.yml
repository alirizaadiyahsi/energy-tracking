name: Performance Tests

on:
  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_scenario:
        description: 'Performance test scenario'
        required: true
        default: 'medium'
        type: choice
        options:
          - light
          - medium
          - heavy
          - stress
          - spike
      target_environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      duration:
        description: 'Test duration (e.g., 300s, 5m)'
        required: false
        default: '300s'

env:
  PYTHON_VERSION: '3.11'

jobs:
  performance-tests:
    name: Performance Testing
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    strategy:
      matrix:
        scenario: ${{ github.event_name == 'workflow_dispatch' && fromJSON('["' + github.event.inputs.test_scenario + '"]') || fromJSON('["light", "medium", "heavy"]') }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache Python dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-performance-${{ hashFiles('**/test-requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-performance-
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r tests/test-requirements.txt
        pip install locust
        
    - name: Set environment variables
      run: |
        case "${{ github.event.inputs.target_environment || 'staging' }}" in
          "staging")
            echo "TARGET_HOST=https://staging-api.energy-tracking.com" >> $GITHUB_ENV
            echo "FRONTEND_HOST=https://staging.energy-tracking.com" >> $GITHUB_ENV
            ;;
          "production")
            echo "TARGET_HOST=https://api.energy-tracking.com" >> $GITHUB_ENV
            echo "FRONTEND_HOST=https://energy-tracking.com" >> $GITHUB_ENV
            ;;
          *)
            echo "TARGET_HOST=http://localhost:8000" >> $GITHUB_ENV
            echo "FRONTEND_HOST=http://localhost:3000" >> $GITHUB_ENV
            ;;
        esac
        
    - name: Health check target environment
      run: |
        echo "Checking health of $TARGET_HOST"
        curl -f "$TARGET_HOST/health" || {
          echo "‚ùå Target environment is not healthy"
          exit 1
        }
        echo "‚úÖ Target environment is healthy"
        
    - name: Run performance tests - ${{ matrix.scenario }}
      env:
        SCENARIO: ${{ matrix.scenario }}
        DURATION: ${{ github.event.inputs.duration || '300s' }}
      run: |
        mkdir -p performance-results
        
        echo "üöÄ Running $SCENARIO performance test..."
        echo "Target: $TARGET_HOST"
        echo "Duration: $DURATION"
        
        # Set scenario-specific parameters
        case "$SCENARIO" in
          "light")
            USERS=10
            SPAWN_RATE=2
            ;;
          "medium")
            USERS=50
            SPAWN_RATE=10
            ;;
          "heavy")
            USERS=200
            SPAWN_RATE=20
            ;;
          "stress")
            USERS=500
            SPAWN_RATE=50
            ;;
          "spike")
            USERS=300
            SPAWN_RATE=150
            ;;
        esac
        
        python tests/performance/run_performance_tests.py \
          --scenario $SCENARIO \
          --host $TARGET_HOST \
          --users $USERS \
          --spawn-rate $SPAWN_RATE \
          --run-time $DURATION \
          --headless \
          --output-dir performance-results
          
    - name: Parse performance results
      run: |
        python .github/scripts/parse_performance_results.py \
          --results-dir performance-results \
          --scenario ${{ matrix.scenario }} \
          --output performance-summary-${{ matrix.scenario }}.json
          
    - name: Check performance thresholds
      run: |
        python .github/scripts/check_performance_thresholds.py \
          --results performance-summary-${{ matrix.scenario }}.json \
          --scenario ${{ matrix.scenario }}
          
    - name: Upload performance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-results-${{ matrix.scenario }}
        path: |
          performance-results/
          performance-summary-${{ matrix.scenario }}.json
          
    - name: Generate performance report
      if: always()
      run: |
        python .github/scripts/generate_performance_report.py \
          --results performance-summary-${{ matrix.scenario }}.json \
          --scenario ${{ matrix.scenario }} \
          --output performance-report-${{ matrix.scenario }}.html

  performance-summary:
    name: Performance Summary
    runs-on: ubuntu-latest
    needs: performance-tests
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download all performance results
      uses: actions/download-artifact@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Generate combined performance report
      run: |
        python .github/scripts/combine_performance_reports.py \
          --input-dir . \
          --output performance-dashboard.html
          
    - name: Upload combined report
      uses: actions/upload-artifact@v4
      with:
        name: performance-dashboard
        path: performance-dashboard.html
        
    - name: Store performance metrics
      if: github.event_name == 'schedule'
      run: |
        # Store metrics in a time-series format for trend analysis
        python .github/scripts/store_performance_metrics.py \
          --results-dir . \
          --timestamp $(date -u +"%Y-%m-%dT%H:%M:%SZ")
          
    - name: Notify on performance degradation
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const issue = await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `üö® Performance Degradation Detected - ${new Date().toISOString().split('T')[0]}`,
            body: `## Performance Test Failure
            
            **Date:** ${new Date().toISOString()}
            **Environment:** ${{ github.event.inputs.target_environment || 'staging' }}
            **Workflow:** [${context.runId}](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            
            The automated performance tests have detected degradation in system performance.
            
            ### Next Steps:
            1. Review the performance test results
            2. Investigate potential causes
            3. Check system resources and scaling
            4. Validate recent deployments
            
            ### Resources:
            - [Performance Dashboard](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            - [Monitoring Dashboard](https://grafana.energy-tracking.com)
            
            **Auto-generated by Performance Testing Workflow**
            `,
            labels: ['performance', 'urgent', 'automated']
          });
          
          console.log(`Created issue #${issue.data.number}`);

  trend-analysis:
    name: Performance Trend Analysis
    runs-on: ubuntu-latest
    needs: performance-summary
    if: github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install analysis dependencies
      run: |
        pip install pandas matplotlib seaborn plotly
        
    - name: Download historical data
      run: |
        # Download performance metrics from the last 30 days
        python .github/scripts/download_historical_metrics.py \
          --days 30 \
          --output historical-metrics.json
          
    - name: Generate trend analysis
      run: |
        python .github/scripts/analyze_performance_trends.py \
          --historical-data historical-metrics.json \
          --output trend-analysis.html
          
    - name: Upload trend analysis
      uses: actions/upload-artifact@v4
      with:
        name: performance-trend-analysis
        path: |
          trend-analysis.html
          historical-metrics.json
          
    - name: Update performance dashboard
      run: |
        # Update the GitHub Pages performance dashboard
        python .github/scripts/update_performance_dashboard.py \
          --trend-analysis trend-analysis.html \
          --latest-results performance-dashboard.html
